{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d1bb596",
   "metadata": {},
   "source": [
    "# FakeScope: Fact-Check + LLM Review Pipeline\n",
    "\n",
    "This notebook builds a pipeline to: (3) compare your model's prediction against Google Fact Check results, (4) produce a teacher–student LLM review, (5) explain why a claim is not fake (when applicable), and (6) ask an LLM to reflect on your model (prompt engineering hints).\n",
    "\n",
    "Environment variables required"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43eb9281",
   "metadata": {},
   "source": [
    "## Notes\n",
    "- If you see warnings about missing `openai` or `joblib`, install them in your environment (e.g., `pip install openai joblib`).\n",
    "- Set secrets via environment variables, not in notebooks: \n",
    "  - macOS zsh example: `export OPENAI_API_KEY=...` `export GOOGLE_FACTCHECK_API_KEY=...`\n",
    "- The baseline block auto-loads `tfidf_vectorizer.joblib` and `best_baseline_model.joblib` if present next to this notebook. If absent, it returns a neutral prediction.\n",
    "- You can switch the LLM model name in the pipeline init to any compatible chat model available to your OpenAI account or proxy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3da212",
   "metadata": {},
   "source": [
    "## Setup and usage (README)\n",
    "\n",
    "### 1) Install dependencies\n",
    "\n",
    "Use your Python environment (3.9+ recommended) and install from `requirements.txt`:\n",
    "\n",
    "```bash\n",
    "# macOS (zsh)\n",
    "python3 -m venv .venv\n",
    "source .venv/bin/activate\n",
    "pip install --upgrade pip\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "Note: On Apple Silicon, PyTorch wheels are available via pip; if you face issues, visit: https://pytorch.org/get-started/locally/\n",
    "\n",
    "### 2) Configure environment variables\n",
    "\n",
    "Set secrets using environment variables before running the notebook:\n",
    "\n",
    "```bash\n",
    "export OPENAI_API_KEY=\"<your-openai-key>\"\n",
    "# Optional if you route through a proxy or Azure/OpenAI-compatible endpoint\n",
    "# export OPENAI_API_BASE=\"https://your-custom-base/v1\"\n",
    "\n",
    "export GOOGLE_FACTCHECK_API_KEY=\"<your-google-factcheck-api-key>\"\n",
    "```\n",
    "\n",
    "### 3) Local models (optional)\n",
    "\n",
    "Place your fine-tuned transformers under one of the following folders (already in this repo):\n",
    "- `distilbert_news_adapted/`\n",
    "- `distilbert_fakenews_2stage/`\n",
    "- `distilbert_fakenews/`\n",
    "\n",
    "The pipeline prefers transformer predictions and falls back to the baseline (`tfidf_vectorizer.joblib` + `best_baseline_model.joblib`) if no transformer is found.\n",
    "\n",
    "### 4) Run the pipeline\n",
    "\n",
    "Execute the example cell in this notebook (last code cell) or call `FakeScopePipeline(...).run(text)` on your own input.\n",
    "\n",
    "### 5) Caching\n",
    "\n",
    "Fact check results are cached in `factcheck_cache.json` for 24 hours to reduce API calls. You can delete the file to clear the cache.\n",
    "\n",
    "### 6) Output validation\n",
    "\n",
    "The pipeline’s output is validated against a JSON Schema when `jsonschema` is installed. The fields `schema_valid` and `schema_error` summarize the validation result.\n",
    "\n",
    "### 7) Troubleshooting\n",
    "\n",
    "- If you see `openai` not found, install with `pip install openai` or re-run `pip install -r requirements.txt`.\n",
    "- If transformer loading fails, ensure the model folders contain `config.json` and `model.safetensors` (and tokenizer files if needed).\n",
    "- To disable transformer predictions and use only the baseline, initialize the pipeline with `use_transformer=False`.\n",
    "- If the Google API returns empty results, try a shorter, more direct claim string or adjust `language_code`.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
