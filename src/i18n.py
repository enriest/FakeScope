"""
Internationalization (i18n) module for FakeScope
Supports: English (default), Spanish, French, German, Russian, Portuguese
"""
import os
import requests
from typing import Optional

# Translation dictionary
TRANSLATIONS = {
    "en": {
        # App title and main UI
        "app_title": "FakeScope ‚Äì Fake News Detector",
        "analyze_tab": "üîç Analyze",
        "chat_tab": "üí¨ Chat & Debate",
        "compare_tab": "‚öñÔ∏è Compare Models",
        "deep_analysis_tab": "üìä Deep Analysis",
        "dashboard_tab": "üìà Dashboard",
        
        # Language selector
        "language": "Language",
        
        # Analyze section
        "analyze_subtitle": "Analyze an article or claim",
        "choose_ai_model": "Choose your AI Model",
        "llm_provider": "LLM Provider",
        "why_provider": "Why",
        "strengths": "Strengths:",
        "cost": "Cost:",
        "article_url": "Article URL (optional)",
        "title_optional": "Title (optional)",
        "article_text": "Article text or claim",
        "fact_check_language": "Fact Check Language",
        "auto_translate": "Auto-translate to English",
        "fetch_from_url": "Fetch text from URL",
        "extracted_text": "Extracted text",
        "run_analysis": "üöÄ Run Analysis",
        "clear": "üóëÔ∏è Clear",
        "provide_input_error": "‚ö†Ô∏è Please provide a URL, title, or text to analyze.",
        "analyzing": "üîÑ Analyzing with",
        "extracted_success": "‚úÖ Extracted text from URL",
        "extract_failed": "‚ö†Ô∏è Could not extract text",
        
        # Results section
        "results": "üìä Results",
        "verdict": "Verdict:",
        "true": "TRUE",
        "fake": "FAKE",
        "credibility_score": "Credibility Score",
        "fake_probability": "Fake Probability",
        "true_probability": "True Probability",
        "translated_info": "‚úÖ Text was translated from {lang} to English for analysis",
        
        # External fact checks
        "external_fact_checks": "üåê External Fact Checks",
        "google_fact_check_score": "Google Fact Check Score",
        "claim": "Claim",
        "rating": "Rating",
        "publisher": "Publisher",
        "review_date": "Review Date",
        "no_fact_checks": "No external fact checks found for this claim.",
        
        # LLM Explanation
        "llm_explanation": "ü§ñ AI Explanation",
        "provided_by": "Provided by",
        
        # Chat section
        "start_conversation": "Start a conversation about the analysis",
        "chat_subtitle": "Discuss and debate the credibility of your analyzed claim",
        "analyze_first": "üëà Please run an analysis first in the **Analyze** tab",
        "current_verdict": "Current Verdict",
        "your_message": "Your message",
        "send": "Send",
        "chat_history": "Chat History",
        
        # Compare models
        "compare_subtitle": "Compare results from all three AI models side-by-side",
        "input_to_compare": "Enter text to compare across models",
        "compare_button": "‚öñÔ∏è Compare All Models",
        "comparing": "Comparing across OpenAI, Gemini, and Perplexity...",
        "model_comparison": "Model Comparison Results",
        "model": "Model",
        "response": "Response",
        "response_time": "Response Time",
        "seconds": "seconds",
        
        # Deep analysis
        "deep_analysis_subtitle": "Get comprehensive analysis with sources and related news",
        "deep_analysis_button": "üîç Run Deep Analysis",
        "deep_analyzing": "Running deep analysis...",
        "sources_found": "Sources Found",
        "related_articles": "Related Articles",
        "sentiment_analysis": "Sentiment Analysis",
        "key_entities": "Key Entities",
        
        # Dashboard
        "dashboard_subtitle": "Recent analyses and statistics",
        "recent_analyses": "Recent Analyses",
        "no_data": "No data available yet. Run some analyses first!",
        "total_analyses": "Total Analyses",
        "avg_credibility": "Average Credibility",
        "most_used_provider": "Most Used Provider",

        # Provider details (names remain from LLM_PROVIDERS)
        "provider_openai_description": "Best for structured, reliable analysis. Excels at following instructions and generating well-formatted explanations.",
        "provider_openai_strengths": "‚Ä¢ Consistent quality\n‚Ä¢ Fast responses (1-2s)\n‚Ä¢ Excellent for professional fact-checking",
        "provider_gemini_description": "Best for high-volume usage and cost savings. Free tier with 1,500 requests/day. Fast and natural language understanding.",
        "provider_gemini_strengths": "‚Ä¢ FREE tier available\n‚Ä¢ Very fast responses\n‚Ä¢ Natural, conversational tone\n‚Ä¢ Multimodal capable",
        "provider_perplexity_description": "Best for current events and recent news. Includes real-time web search, providing up-to-date context and additional sources.",
        "provider_perplexity_strengths": "‚Ä¢ Real-time web search\n‚Ä¢ Latest information\n‚Ä¢ Automatically cites sources\n‚Ä¢ Great for breaking news",

        # External links / labels
        "view_source": "View Source",

        # Chat quick prompts
        "quick_prompts_title": "üí° Quick Prompts",
        "quick_prompt_why": "Why is this fake/true?",
        "quick_prompt_evidence": "Show me evidence",
        "quick_prompt_disagree": "I disagree",
        "quick_prompt_msg_why": "Explain in detail why you think this claim is fake or true.",
        "quick_prompt_msg_evidence": "What specific evidence supports or contradicts this claim?",
        "quick_prompt_msg_disagree": "I disagree with your assessment. Can you consider alternative perspectives?",

        # Deep analysis section
        "source_analysis": "üì∞ Source Analysis",
        "found_fact_checks_count": "Found {count} external fact-checks",
        "rating_breakdown": "Rating Breakdown",
        "detailed_sources": "Detailed Sources",
        "source_item": "Source {idx}: {publisher}",
        "rating_label": "Rating",
        "claim_label": "Claim",
        "url_label": "URL",
        "review_date_label": "Review Date",
        "no_external_sources": "No external sources found. This claim may be too recent or too specific.",
        "model_confidence": "üéØ Model Confidence",
        "text_statistics": "üìà Text Statistics",
        "characters": "Characters",
        "words": "Words",
        "sentences": "Sentences",
        "avg_word_length": "Avg Word Length",
        "key_topics": "üè∑Ô∏è Key Topics",
        "no_keywords_identified": "No significant keywords identified",
        "provider_changed_run_again": "LLM provider changed. Click 'Run Analysis' to generate a new explanation.",
    },
    
    "es": {
        # App title and main UI
        "app_title": "FakeScope ‚Äì Detector de Noticias Falsas",
        "analyze_tab": "üîç Analizar",
        "chat_tab": "üí¨ Chat y Debate",
        "compare_tab": "‚öñÔ∏è Comparar Modelos",
        "deep_analysis_tab": "üìä An√°lisis Profundo",
        "dashboard_tab": "üìà Panel",
        
        # Language selector
        "language": "Idioma",
        
        # Analyze section
        "analyze_subtitle": "Analizar un art√≠culo o afirmaci√≥n",
        "choose_ai_model": "Elige tu Modelo de IA",
        "llm_provider": "Proveedor LLM",
        "why_provider": "Por qu√©",
        "strengths": "Fortalezas:",
        "cost": "Costo:",
        "article_url": "URL del art√≠culo (opcional)",
        "title_optional": "T√≠tulo (opcional)",
        "article_text": "Texto del art√≠culo o afirmaci√≥n",
        "fact_check_language": "Idioma de Verificaci√≥n",
        "auto_translate": "Traducir autom√°ticamente al ingl√©s",
        "fetch_from_url": "Obtener texto de la URL",
        "extracted_text": "Texto extra√≠do",
        "run_analysis": "üöÄ Ejecutar An√°lisis",
        "clear": "üóëÔ∏è Limpiar",
        "provide_input_error": "‚ö†Ô∏è Por favor proporciona una URL, t√≠tulo o texto para analizar.",
        "analyzing": "üîÑ Analizando con",
        "extracted_success": "‚úÖ Texto extra√≠do de la URL",
        "extract_failed": "‚ö†Ô∏è No se pudo extraer el texto",
        
        # Results section
        "results": "üìä Resultados",
        "verdict": "Veredicto:",
        "true": "VERDADERO",
        "fake": "FALSO",
        "credibility_score": "Puntuaci√≥n de Credibilidad",
        "fake_probability": "Probabilidad Falso",
        "true_probability": "Probabilidad Verdadero",
        "translated_info": "‚úÖ El texto fue traducido de {lang} al ingl√©s para el an√°lisis",
        
        # External fact checks
        "external_fact_checks": "üåê Verificaciones Externas",
        "google_fact_check_score": "Puntuaci√≥n Google Fact Check",
        "claim": "Afirmaci√≥n",
        "rating": "Calificaci√≥n",
        "publisher": "Editor",
        "review_date": "Fecha de Revisi√≥n",
        "no_fact_checks": "No se encontraron verificaciones externas para esta afirmaci√≥n.",
        
        # LLM Explanation
        "llm_explanation": "ü§ñ Explicaci√≥n de IA",
        "provided_by": "Proporcionado por",
        
        # Chat section
        "start_conversation": "Iniciar una conversaci√≥n sobre el an√°lisis",
        "chat_subtitle": "Discutir y debatir la credibilidad de tu afirmaci√≥n analizada",
        "analyze_first": "üëà Por favor ejecuta un an√°lisis primero en la pesta√±a **Analizar**",
        "current_verdict": "Veredicto Actual",
        "your_message": "Tu mensaje",
        "send": "Enviar",
        "chat_history": "Historial de Chat",
        
        # Compare models
        "compare_subtitle": "Compara resultados de los tres modelos de IA lado a lado",
        "input_to_compare": "Ingresa texto para comparar entre modelos",
        "compare_button": "‚öñÔ∏è Comparar Todos los Modelos",
        "comparing": "Comparando entre OpenAI, Gemini y Perplexity...",
        "model_comparison": "Resultados de Comparaci√≥n de Modelos",
        "model": "Modelo",
        "response": "Respuesta",
        "response_time": "Tiempo de Respuesta",
        "seconds": "segundos",
        
        # Deep analysis
        "deep_analysis_subtitle": "Obt√©n an√°lisis completo con fuentes y noticias relacionadas",
        "deep_analysis_button": "üîç Ejecutar An√°lisis Profundo",
        "deep_analyzing": "Ejecutando an√°lisis profundo...",
        "sources_found": "Fuentes Encontradas",
        "related_articles": "Art√≠culos Relacionados",
        "sentiment_analysis": "An√°lisis de Sentimiento",
        "key_entities": "Entidades Clave",
        
        # Dashboard
        "dashboard_subtitle": "An√°lisis recientes y estad√≠sticas",
        "recent_analyses": "An√°lisis Recientes",
        "no_data": "¬°No hay datos disponibles a√∫n. Ejecuta algunos an√°lisis primero!",
        "total_analyses": "Total de An√°lisis",
        "avg_credibility": "Credibilidad Promedio",
        "most_used_provider": "Proveedor M√°s Usado",

        # Provider details
        "provider_openai_description": "Ideal para an√°lisis estructurado y confiable. Destaca en seguir instrucciones y generar explicaciones bien formateadas.",
        "provider_openai_strengths": "‚Ä¢ Calidad constante\n‚Ä¢ Respuestas r√°pidas (1-2s)\n‚Ä¢ Excelente para verificaci√≥n profesional",
        "provider_gemini_description": "Ideal para alto volumen y ahorro de costos. Plan gratuito con 1.500 solicitudes/d√≠a. R√°pido y con comprensi√≥n natural del lenguaje.",
        "provider_gemini_strengths": "‚Ä¢ Plan GRATIS disponible\n‚Ä¢ Respuestas muy r√°pidas\n‚Ä¢ Tono natural y conversacional\n‚Ä¢ Capaz de trabajar con m√∫ltiples modalidades",
        "provider_perplexity_description": "Ideal para eventos actuales y noticias recientes. Incluye b√∫squeda web en tiempo real, ofreciendo contexto actualizado y fuentes adicionales.",
        "provider_perplexity_strengths": "‚Ä¢ B√∫squeda web en tiempo real\n‚Ä¢ Informaci√≥n m√°s reciente\n‚Ä¢ Cita fuentes autom√°ticamente\n‚Ä¢ Excelente para noticias de √∫ltima hora",

        # External links / labels
        "view_source": "Ver Fuente",

        # Chat quick prompts
        "quick_prompts_title": "üí° Sugerencias R√°pidas",
        "quick_prompt_why": "¬øPor qu√© es falso/verdadero?",
        "quick_prompt_evidence": "Mu√©strame evidencia",
        "quick_prompt_disagree": "No estoy de acuerdo",
        "quick_prompt_msg_why": "Explica en detalle por qu√© crees que esta afirmaci√≥n es falsa o verdadera.",
        "quick_prompt_msg_evidence": "¬øQu√© evidencia espec√≠fica apoya o contradice esta afirmaci√≥n?",
        "quick_prompt_msg_disagree": "No estoy de acuerdo con tu evaluaci√≥n. ¬øPuedes considerar perspectivas alternativas?",

        # Deep analysis section
        "source_analysis": "üì∞ An√°lisis de Fuentes",
        "found_fact_checks_count": "Se encontraron {count} verificaciones externas",
        "rating_breakdown": "Desglose de Calificaciones",
        "detailed_sources": "Fuentes Detalladas",
        "source_item": "Fuente {idx}: {publisher}",
        "rating_label": "Calificaci√≥n",
        "claim_label": "Afirmaci√≥n",
        "url_label": "URL",
        "review_date_label": "Fecha de Revisi√≥n",
        "no_external_sources": "No se encontraron fuentes externas. Esta afirmaci√≥n puede ser demasiado reciente o espec√≠fica.",
        "model_confidence": "üéØ Confianza del Modelo",
        "text_statistics": "üìà Estad√≠sticas del Texto",
        "characters": "Caracteres",
        "words": "Palabras",
        "sentences": "Oraciones",
        "avg_word_length": "Longitud Media de Palabra",
        "key_topics": "üè∑Ô∏è Temas Clave",
        "no_keywords_identified": "No se identificaron palabras clave significativas",
        "provider_changed_run_again": "El proveedor de IA cambi√≥. Pulsa 'Ejecutar An√°lisis' para generar una nueva explicaci√≥n.",
    },
    
    "fr": {
        # App title and main UI
        "app_title": "FakeScope ‚Äì D√©tecteur de Fausses Nouvelles",
        "analyze_tab": "üîç Analyser",
        "chat_tab": "üí¨ Chat & D√©bat",
        "compare_tab": "‚öñÔ∏è Comparer les Mod√®les",
        "deep_analysis_tab": "üìä Analyse Approfondie",
        "dashboard_tab": "üìà Tableau de Bord",
        
        # Language selector
        "language": "Langue",
        
        # Analyze section
        "analyze_subtitle": "Analyser un article ou une affirmation",
        "choose_ai_model": "Choisissez votre Mod√®le IA",
        "llm_provider": "Fournisseur LLM",
        "why_provider": "Pourquoi",
        "strengths": "Forces:",
        "cost": "Co√ªt:",
        "article_url": "URL de l'article (optionnel)",
        "title_optional": "Titre (optionnel)",
        "article_text": "Texte de l'article ou affirmation",
        "fact_check_language": "Langue de V√©rification",
        "auto_translate": "Traduire automatiquement en anglais",
        "fetch_from_url": "Extraire le texte de l'URL",
        "extracted_text": "Texte extrait",
        "run_analysis": "üöÄ Lancer l'Analyse",
        "clear": "üóëÔ∏è Effacer",
        "provide_input_error": "‚ö†Ô∏è Veuillez fournir une URL, un titre ou un texte √† analyser.",
        "analyzing": "üîÑ Analyse avec",
        "extracted_success": "‚úÖ Texte extrait de l'URL",
        "extract_failed": "‚ö†Ô∏è Impossible d'extraire le texte",
        
        # Results section
        "results": "üìä R√©sultats",
        "verdict": "Verdict:",
        "true": "VRAI",
        "fake": "FAUX",
        "credibility_score": "Score de Cr√©dibilit√©",
        "fake_probability": "Probabilit√© Faux",
        "true_probability": "Probabilit√© Vrai",
        "translated_info": "‚úÖ Le texte a √©t√© traduit de {lang} vers l'anglais pour l'analyse",
        
        # External fact checks
        "external_fact_checks": "üåê V√©rifications Externes",
        "google_fact_check_score": "Score Google Fact Check",
        "claim": "Affirmation",
        "rating": "√âvaluation",
        "publisher": "√âditeur",
        "review_date": "Date de R√©vision",
        "no_fact_checks": "Aucune v√©rification externe trouv√©e pour cette affirmation.",
        
        # LLM Explanation
        "llm_explanation": "ü§ñ Explication IA",
        "provided_by": "Fourni par",
        
        # Chat section
        "start_conversation": "D√©marrer une conversation sur l'analyse",
        "chat_subtitle": "Discuter et d√©battre de la cr√©dibilit√© de votre affirmation analys√©e",
        "analyze_first": "üëà Veuillez d'abord effectuer une analyse dans l'onglet **Analyser**",
        "current_verdict": "Verdict Actuel",
        "your_message": "Votre message",
        "send": "Envoyer",
        "chat_history": "Historique du Chat",
        
        # Compare models
        "compare_subtitle": "Comparez les r√©sultats des trois mod√®les IA c√¥te √† c√¥te",
        "input_to_compare": "Entrez le texte √† comparer entre les mod√®les",
        "compare_button": "‚öñÔ∏è Comparer Tous les Mod√®les",
        "comparing": "Comparaison entre OpenAI, Gemini et Perplexity...",
        "model_comparison": "R√©sultats de Comparaison des Mod√®les",
        "model": "Mod√®le",
        "response": "R√©ponse",
        "response_time": "Temps de R√©ponse",
        "seconds": "secondes",
        
        # Deep analysis
        "deep_analysis_subtitle": "Obtenez une analyse compl√®te avec sources et actualit√©s connexes",
        "deep_analysis_button": "üîç Lancer l'Analyse Approfondie",
        "deep_analyzing": "Ex√©cution de l'analyse approfondie...",
        "sources_found": "Sources Trouv√©es",
        "related_articles": "Articles Connexes",
        "sentiment_analysis": "Analyse de Sentiment",
        "key_entities": "Entit√©s Cl√©s",
        
        # Dashboard
        "dashboard_subtitle": "Analyses r√©centes et statistiques",
        "recent_analyses": "Analyses R√©centes",
        "no_data": "Aucune donn√©e disponible pour le moment. Effectuez d'abord quelques analyses!",
        "total_analyses": "Total des Analyses",
        "avg_credibility": "Cr√©dibilit√© Moyenne",
        "most_used_provider": "Fournisseur le Plus Utilis√©",

        # Provider details
        "provider_openai_description": "Id√©al pour une analyse structur√©e et fiable. Excelle dans le suivi des instructions et la production d'explications bien format√©es.",
        "provider_openai_strengths": "‚Ä¢ Qualit√© constante\n‚Ä¢ R√©ponses rapides (1-2s)\n‚Ä¢ Excellent pour la v√©rification professionnelle",
        "provider_gemini_description": "Id√©al pour des volumes √©lev√©s et des √©conomies. Forfait gratuit avec 1 500 requ√™tes/jour. Rapide et compr√©hension naturelle du langage.",
        "provider_gemini_strengths": "‚Ä¢ Forfait GRATUIT disponible\n‚Ä¢ R√©ponses tr√®s rapides\n‚Ä¢ Ton naturel et conversationnel\n‚Ä¢ Multimodal",
        "provider_perplexity_description": "Id√©al pour l'actualit√© et les nouvelles r√©centes. Inclut une recherche web en temps r√©el, fournissant un contexte √† jour et des sources suppl√©mentaires.",
        "provider_perplexity_strengths": "‚Ä¢ Recherche web en temps r√©el\n‚Ä¢ Informations les plus r√©centes\n‚Ä¢ Cite automatiquement les sources\n‚Ä¢ Excellent pour les derni√®res nouvelles",

        "view_source": "Voir la Source",

        # Chat quick prompts
        "quick_prompts_title": "üí° Suggestions Rapides",
        "quick_prompt_why": "Pourquoi est-ce faux/vrai ?",
        "quick_prompt_evidence": "Montre-moi des preuves",
        "quick_prompt_disagree": "Je ne suis pas d'accord",
        "quick_prompt_msg_why": "Explique en d√©tail pourquoi tu penses que cette affirmation est fausse ou vraie.",
        "quick_prompt_msg_evidence": "Quelles preuves sp√©cifiques soutiennent ou contredisent cette affirmation ?",
        "quick_prompt_msg_disagree": "Je ne suis pas d'accord avec ton √©valuation. Peux-tu consid√©rer des perspectives alternatives ?",

        # Deep analysis
        "source_analysis": "üì∞ Analyse des Sources",
        "found_fact_checks_count": "{count} v√©rifications externes trouv√©es",
        "rating_breakdown": "R√©partition des √âvaluations",
        "detailed_sources": "Sources D√©taill√©es",
        "source_item": "Source {idx} : {publisher}",
        "rating_label": "√âvaluation",
        "claim_label": "Affirmation",
        "url_label": "URL",
        "review_date_label": "Date de R√©vision",
        "no_external_sources": "Aucune source externe trouv√©e. Cette affirmation peut √™tre trop r√©cente ou trop sp√©cifique.",
        "model_confidence": "üéØ Confiance du Mod√®le",
        "text_statistics": "üìà Statistiques du Texte",
        "characters": "Caract√®res",
        "words": "Mots",
        "sentences": "Phrases",
        "avg_word_length": "Longueur Moyenne des Mots",
        "key_topics": "üè∑Ô∏è Sujets Cl√©s",
        "no_keywords_identified": "Aucun mot-cl√© significatif identifi√©",
        "provider_changed_run_again": "Le fournisseur IA a chang√©. Cliquez sur 'Lancer l'Analyse' pour une nouvelle explication.",
    },
    
    "de": {
        # App title and main UI
        "app_title": "FakeScope ‚Äì Fake-News-Detektor",
        "analyze_tab": "üîç Analysieren",
        "chat_tab": "üí¨ Chat & Debatte",
        "compare_tab": "‚öñÔ∏è Modelle Vergleichen",
        "deep_analysis_tab": "üìä Tiefenanalyse",
        "dashboard_tab": "üìà Dashboard",
        
        # Language selector
        "language": "Sprache",
        
        # Analyze section
        "analyze_subtitle": "Einen Artikel oder eine Behauptung analysieren",
        "choose_ai_model": "W√§hlen Sie Ihr KI-Modell",
        "llm_provider": "LLM-Anbieter",
        "why_provider": "Warum",
        "strengths": "St√§rken:",
        "cost": "Kosten:",
        "article_url": "Artikel-URL (optional)",
        "title_optional": "Titel (optional)",
        "article_text": "Artikeltext oder Behauptung",
        "fact_check_language": "Faktencheck-Sprache",
        "auto_translate": "Automatisch ins Englische √ºbersetzen",
        "fetch_from_url": "Text von URL abrufen",
        "extracted_text": "Extrahierter Text",
        "run_analysis": "üöÄ Analyse Starten",
        "clear": "üóëÔ∏è L√∂schen",
        "provide_input_error": "‚ö†Ô∏è Bitte geben Sie eine URL, einen Titel oder Text zur Analyse an.",
        "analyzing": "üîÑ Analysiere mit",
        "extracted_success": "‚úÖ Text von URL extrahiert",
        "extract_failed": "‚ö†Ô∏è Text konnte nicht extrahiert werden",
        
        # Results section
        "results": "üìä Ergebnisse",
        "verdict": "Urteil:",
        "true": "WAHR",
        "fake": "FALSCH",
        "credibility_score": "Glaubw√ºrdigkeitswert",
        "fake_probability": "Wahrscheinlichkeit Falsch",
        "true_probability": "Wahrscheinlichkeit Wahr",
        "translated_info": "‚úÖ Text wurde von {lang} ins Englische f√ºr die Analyse √ºbersetzt",
        
        # External fact checks
        "external_fact_checks": "üåê Externe Faktenchecks",
        "google_fact_check_score": "Google Fact Check Punktzahl",
        "claim": "Behauptung",
        "rating": "Bewertung",
        "publisher": "Herausgeber",
        "review_date": "√úberpr√ºfungsdatum",
        "no_fact_checks": "Keine externen Faktenchecks f√ºr diese Behauptung gefunden.",
        
        # LLM Explanation
        "llm_explanation": "ü§ñ KI-Erkl√§rung",
        "provided_by": "Bereitgestellt von",
        
        # Chat section
        "start_conversation": "Starten Sie eine Unterhaltung √ºber die Analyse",
        "chat_subtitle": "Diskutieren und debattieren Sie die Glaubw√ºrdigkeit Ihrer analysierten Behauptung",
        "analyze_first": "üëà Bitte f√ºhren Sie zuerst eine Analyse im Tab **Analysieren** durch",
        "current_verdict": "Aktuelles Urteil",
        "your_message": "Ihre Nachricht",
        "send": "Senden",
        "chat_history": "Chat-Verlauf",
        
        # Compare models
        "compare_subtitle": "Vergleichen Sie Ergebnisse aller drei KI-Modelle nebeneinander",
        "input_to_compare": "Geben Sie Text ein, um zwischen Modellen zu vergleichen",
        "compare_button": "‚öñÔ∏è Alle Modelle Vergleichen",
        "comparing": "Vergleiche zwischen OpenAI, Gemini und Perplexity...",
        "model_comparison": "Modellvergleich Ergebnisse",
        "model": "Modell",
        "response": "Antwort",
        "response_time": "Antwortzeit",
        "seconds": "Sekunden",
        
        # Deep analysis
        "deep_analysis_subtitle": "Erhalten Sie umfassende Analyse mit Quellen und verwandten Nachrichten",
        "deep_analysis_button": "üîç Tiefenanalyse Starten",
        "deep_analyzing": "F√ºhre Tiefenanalyse durch...",
        "sources_found": "Quellen Gefunden",
        "related_articles": "Verwandte Artikel",
        "sentiment_analysis": "Sentiment-Analyse",
        "key_entities": "Schl√ºsselentit√§ten",
        
        # Dashboard
        "dashboard_subtitle": "Aktuelle Analysen und Statistiken",
        "recent_analyses": "Aktuelle Analysen",
        "no_data": "Noch keine Daten verf√ºgbar. F√ºhren Sie zuerst einige Analysen durch!",
        "total_analyses": "Gesamtanalysen",
        "avg_credibility": "Durchschnittliche Glaubw√ºrdigkeit",
        "most_used_provider": "Am Meisten Verwendeter Anbieter",

        # Provider details
        "provider_openai_description": "Am besten f√ºr strukturierte, zuverl√§ssige Analysen. Hervorragend beim Befolgen von Anweisungen und beim Erstellen gut formatierter Erkl√§rungen.",
        "provider_openai_strengths": "‚Ä¢ Konstante Qualit√§t\n‚Ä¢ Schnelle Antworten (1-2s)\n‚Ä¢ Hervorragend f√ºr professionelle Verifikation",
        "provider_gemini_description": "Am besten f√ºr hohes Volumen und Kosteneinsparungen. Kostenloses Kontingent mit 1.500 Anfragen/Tag. Schnell und mit nat√ºrlichem Sprachverst√§ndnis.",
        "provider_gemini_strengths": "‚Ä¢ KOSTENLOSE Stufe verf√ºgbar\n‚Ä¢ Sehr schnelle Antworten\n‚Ä¢ Nat√ºrlicher, konversationeller Ton\n‚Ä¢ Multimodal f√§hig",
        "provider_perplexity_description": "Am besten f√ºr aktuelle Ereignisse und neueste Nachrichten. Beinhaltet Echtzeit-Websuche und liefert aktuelle Kontexte sowie zus√§tzliche Quellen.",
        "provider_perplexity_strengths": "‚Ä¢ Echtzeit-Websuche\n‚Ä¢ Neueste Informationen\n‚Ä¢ Zitiert Quellen automatisch\n‚Ä¢ Gro√üartig f√ºr Eilmeldungen",

        "view_source": "Quelle anzeigen",

        # Chat quick prompts
        "quick_prompts_title": "üí° Schnelle Vorschl√§ge",
        "quick_prompt_why": "Warum ist das falsch/wahr?",
        "quick_prompt_evidence": "Zeig mir Beweise",
        "quick_prompt_disagree": "Ich stimme nicht zu",
        "quick_prompt_msg_why": "Erl√§utere ausf√ºhrlich, warum diese Behauptung deiner Meinung nach falsch oder wahr ist.",
        "quick_prompt_msg_evidence": "Welche konkreten Beweise st√ºtzen oder widerlegen diese Behauptung?",
        "quick_prompt_msg_disagree": "Ich stimme deiner Bewertung nicht zu. Kannst du alternative Perspektiven ber√ºcksichtigen?",

        # Deep analysis
        "source_analysis": "üì∞ Quellenanalyse",
        "found_fact_checks_count": "{count} externe Faktenchecks gefunden",
        "rating_breakdown": "Bewertungs√ºbersicht",
        "detailed_sources": "Detaillierte Quellen",
        "source_item": "Quelle {idx}: {publisher}",
        "rating_label": "Bewertung",
        "claim_label": "Aussage",
        "url_label": "URL",
        "review_date_label": "Bewertungsdatum",
        "no_external_sources": "Keine externen Quellen gefunden. Diese Aussage ist m√∂glicherweise zu neu oder zu spezifisch.",
        "model_confidence": "üéØ Modellvertrauen",
        "text_statistics": "üìà Textstatistiken",
        "characters": "Zeichen",
        "words": "W√∂rter",
        "sentences": "S√§tze",
        "avg_word_length": "Durchschn. Wortl√§nge",
        "key_topics": "üè∑Ô∏è Schl√ºsselthemen",
        "no_keywords_identified": "Keine bedeutenden Schl√ºsselw√∂rter identifiziert",
        "provider_changed_run_again": "LLM-Anbieter ge√§ndert. Klicken Sie auf 'Analyse Starten' f√ºr eine neue Erkl√§rung.",
    },
    
    "ru": {
        # App title and main UI
        "app_title": "FakeScope ‚Äì –î–µ—Ç–µ–∫—Ç–æ—Ä –§–µ–π–∫–æ–≤—ã—Ö –ù–æ–≤–æ—Å—Ç–µ–π",
        "analyze_tab": "üîç –ê–Ω–∞–ª–∏–∑",
        "chat_tab": "üí¨ –ß–∞—Ç –∏ –î–µ–±–∞—Ç—ã",
        "compare_tab": "‚öñÔ∏è –°—Ä–∞–≤–Ω–∏—Ç—å –ú–æ–¥–µ–ª–∏",
        "deep_analysis_tab": "üìä –ì–ª—É–±–æ–∫–∏–π –ê–Ω–∞–ª–∏–∑",
        "dashboard_tab": "üìà –ü–∞–Ω–µ–ª—å",
        
        # Language selector
        "language": "–Ø–∑—ã–∫",
        
        # Analyze section
        "analyze_subtitle": "–ê–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Å—Ç–∞—Ç—å—é –∏–ª–∏ —É—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ",
        "choose_ai_model": "–í—ã–±–µ—Ä–∏—Ç–µ –≤–∞—à—É AI –ú–æ–¥–µ–ª—å",
        "llm_provider": "–ü—Ä–æ–≤–∞–π–¥–µ—Ä LLM",
        "why_provider": "–ü–æ—á–µ–º—É",
        "strengths": "–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞:",
        "cost": "–°—Ç–æ–∏–º–æ—Å—Ç—å:",
        "article_url": "URL —Å—Ç–∞—Ç—å–∏ (–Ω–µ–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ)",
        "title_optional": "–ó–∞–≥–æ–ª–æ–≤–æ–∫ (–Ω–µ–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ)",
        "article_text": "–¢–µ–∫—Å—Ç —Å—Ç–∞—Ç—å–∏ –∏–ª–∏ —É—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ",
        "fact_check_language": "–Ø–∑—ã–∫ –ü—Ä–æ–≤–µ—Ä–∫–∏ –§–∞–∫—Ç–æ–≤",
        "auto_translate": "–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø–µ—Ä–µ–≤–æ–¥–∏—Ç—å –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–∏–π",
        "fetch_from_url": "–ò–∑–≤–ª–µ—á—å —Ç–µ–∫—Å—Ç –∏–∑ URL",
        "extracted_text": "–ò–∑–≤–ª–µ—á—ë–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç",
        "run_analysis": "üöÄ –ó–∞–ø—É—Å—Ç–∏—Ç—å –ê–Ω–∞–ª–∏–∑",
        "clear": "üóëÔ∏è –û—á–∏—Å—Ç–∏—Ç—å",
        "provide_input_error": "‚ö†Ô∏è –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø—Ä–µ–¥–æ—Å—Ç–∞–≤—å—Ç–µ URL, –∑–∞–≥–æ–ª–æ–≤–æ–∫ –∏–ª–∏ —Ç–µ–∫—Å—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞.",
        "analyzing": "üîÑ –ê–Ω–∞–ª–∏–∑ —Å –ø–æ–º–æ—â—å—é",
        "extracted_success": "‚úÖ –¢–µ–∫—Å—Ç –∏–∑–≤–ª–µ—á—ë–Ω –∏–∑ URL",
        "extract_failed": "‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å —Ç–µ–∫—Å—Ç",
        
        # Results section
        "results": "üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã",
        "verdict": "–í–µ—Ä–¥–∏–∫—Ç:",
        "true": "–ü–†–ê–í–î–ê",
        "fake": "–õ–û–ñ–¨",
        "credibility_score": "–û—Ü–µ–Ω–∫–∞ –î–æ—Å—Ç–æ–≤–µ—Ä–Ω–æ—Å—Ç–∏",
        "fake_probability": "–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –õ–∂–∏",
        "true_probability": "–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –ü—Ä–∞–≤–¥—ã",
        "translated_info": "‚úÖ –¢–µ–∫—Å—Ç –±—ã–ª –ø–µ—Ä–µ–≤–µ–¥—ë–Ω —Å {lang} –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–∏–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞",
        
        # External fact checks
        "external_fact_checks": "üåê –í–Ω–µ—à–Ω–∏–µ –ü—Ä–æ–≤–µ—Ä–∫–∏ –§–∞–∫—Ç–æ–≤",
        "google_fact_check_score": "–û—Ü–µ–Ω–∫–∞ Google Fact Check",
        "claim": "–£—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ",
        "rating": "–†–µ–π—Ç–∏–Ω–≥",
        "publisher": "–ò–∑–¥–∞—Ç–µ–ª—å",
        "review_date": "–î–∞—Ç–∞ –ü—Ä–æ–≤–µ—Ä–∫–∏",
        "no_fact_checks": "–í–Ω–µ—à–Ω–∏–µ –ø—Ä–æ–≤–µ—Ä–∫–∏ —Ñ–∞–∫—Ç–æ–≤ –¥–ª—è —ç—Ç–æ–≥–æ —É—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω—ã.",
        
        # LLM Explanation
        "llm_explanation": "ü§ñ –û–±—ä—è—Å–Ω–µ–Ω–∏–µ AI",
        "provided_by": "–ü—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–æ",
        
        # Chat section
        "start_conversation": "–ù–∞—á–∞—Ç—å —Ä–∞–∑–≥–æ–≤–æ—Ä –æ–± –∞–Ω–∞–ª–∏–∑–µ",
        "chat_subtitle": "–û–±—Å—É–¥–∏—Ç—å –∏ –æ—Å–ø–æ—Ä–∏—Ç—å –¥–æ—Å—Ç–æ–≤–µ—Ä–Ω–æ—Å—Ç—å –≤–∞—à–µ–≥–æ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —É—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è",
        "analyze_first": "üëà –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —Å–Ω–∞—á–∞–ª–∞ –≤—ã–ø–æ–ª–Ω–∏—Ç–µ –∞–Ω–∞–ª–∏–∑ –Ω–∞ –≤–∫–ª–∞–¥–∫–µ **–ê–Ω–∞–ª–∏–∑**",
        "current_verdict": "–¢–µ–∫—É—â–∏–π –í–µ—Ä–¥–∏–∫—Ç",
        "your_message": "–í–∞—à–µ —Å–æ–æ–±—â–µ–Ω–∏–µ",
        "send": "–û—Ç–ø—Ä–∞–≤–∏—Ç—å",
        "chat_history": "–ò—Å—Ç–æ—Ä–∏—è –ß–∞—Ç–∞",
        
        # Compare models
        "compare_subtitle": "–°—Ä–∞–≤–Ω–∏—Ç–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤—Å–µ—Ö —Ç—Ä—ë—Ö AI –º–æ–¥–µ–ª–µ–π",
        "input_to_compare": "–í–≤–µ–¥–∏—Ç–µ —Ç–µ–∫—Å—Ç –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –º–µ–∂–¥—É –º–æ–¥–µ–ª—è–º–∏",
        "compare_button": "‚öñÔ∏è –°—Ä–∞–≤–Ω–∏—Ç—å –í—Å–µ –ú–æ–¥–µ–ª–∏",
        "comparing": "–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–µ–∂–¥—É OpenAI, Gemini –∏ Perplexity...",
        "model_comparison": "–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –°—Ä–∞–≤–Ω–µ–Ω–∏—è –ú–æ–¥–µ–ª–µ–π",
        "model": "–ú–æ–¥–µ–ª—å",
        "response": "–û—Ç–≤–µ—Ç",
        "response_time": "–í—Ä–µ–º—è –û—Ç–≤–µ—Ç–∞",
        "seconds": "—Å–µ–∫—É–Ω–¥",
        
        # Deep analysis
        "deep_analysis_subtitle": "–ü–æ–ª—É—á–∏—Ç–µ –ø–æ–ª–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Å –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º–∏ –∏ —Å–≤—è–∑–∞–Ω–Ω—ã–º–∏ –Ω–æ–≤–æ—Å—Ç—è–º–∏",
        "deep_analysis_button": "üîç –ó–∞–ø—É—Å—Ç–∏—Ç—å –ì–ª—É–±–æ–∫–∏–π –ê–Ω–∞–ª–∏–∑",
        "deep_analyzing": "–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –≥–ª—É–±–æ–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞...",
        "sources_found": "–ù–∞–π–¥–µ–Ω–æ –ò—Å—Ç–æ—á–Ω–∏–∫–æ–≤",
        "related_articles": "–°–≤—è–∑–∞–Ω–Ω—ã–µ –°—Ç–∞—Ç—å–∏",
        "sentiment_analysis": "–ê–Ω–∞–ª–∏–∑ –¢–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏",
        "key_entities": "–ö–ª—é—á–µ–≤—ã–µ –°—É—â–Ω–æ—Å—Ç–∏",
        
        # Dashboard
        "dashboard_subtitle": "–ü–æ—Å–ª–µ–¥–Ω–∏–µ –∞–Ω–∞–ª–∏–∑—ã –∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞",
        "recent_analyses": "–ü–æ—Å–ª–µ–¥–Ω–∏–µ –ê–Ω–∞–ª–∏–∑—ã",
        "no_data": "–î–∞–Ω–Ω—ã–µ –ø–æ–∫–∞ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã. –°–Ω–∞—á–∞–ª–∞ –≤—ã–ø–æ–ª–Ω–∏—Ç–µ –Ω–µ—Å–∫–æ–ª—å–∫–æ –∞–Ω–∞–ª–∏–∑–æ–≤!",
        "total_analyses": "–í—Å–µ–≥–æ –ê–Ω–∞–ª–∏–∑–æ–≤",
        "avg_credibility": "–°—Ä–µ–¥–Ω—è—è –î–æ—Å—Ç–æ–≤–µ—Ä–Ω–æ—Å—Ç—å",
        "most_used_provider": "–ù–∞–∏–±–æ–ª–µ–µ –ò—Å–ø–æ–ª—å–∑—É–µ–º—ã–π –ü—Ä–æ–≤–∞–π–¥–µ—Ä",

        # Provider details
        "provider_openai_description": "–õ—É—á—à–µ –≤—Å–µ–≥–æ –ø–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –∏ –Ω–∞–¥–µ–∂–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞. –û—Ç–ª–∏—á–Ω–æ —Å–ª–µ–¥—É–µ—Ç –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è–º –∏ —Å–æ–∑–¥–∞–µ—Ç —Ö–æ—Ä–æ—à–æ –æ—Ñ–æ—Ä–º–ª–µ–Ω–Ω—ã–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏—è.",
        "provider_openai_strengths": "‚Ä¢ –°—Ç–∞–±–∏–ª—å–Ω–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ\n‚Ä¢ –ë—ã—Å—Ç—Ä—ã–µ –æ—Ç–≤–µ—Ç—ã (1-2—Å)\n‚Ä¢ –û—Ç–ª–∏—á–Ω–æ –¥–ª—è –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏",
        "provider_gemini_description": "–ü–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è –±–æ–ª—å—à–æ–≥–æ –æ–±—ä–µ–º–∞ –∏ —ç–∫–æ–Ω–æ–º–∏–∏. –ë–µ—Å–ø–ª–∞—Ç–Ω—ã–π —Ç–∞—Ä–∏—Ñ —Å 1 500 –∑–∞–ø—Ä–æ—Å–∞–º–∏/–¥–µ–Ω—å. –ë—ã—Å—Ç—Ä—ã–π –∏ —Ö–æ—Ä–æ—à–æ –ø–æ–Ω–∏–º–∞–µ—Ç –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω—ã–π —è–∑—ã–∫.",
        "provider_gemini_strengths": "‚Ä¢ –î–æ—Å—Ç—É–ø–µ–Ω –ë–ï–°–ü–õ–ê–¢–ù–´–ô —Ç–∞—Ä–∏—Ñ\n‚Ä¢ –û—á–µ–Ω—å –±—ã—Å—Ç—Ä—ã–µ –æ—Ç–≤–µ—Ç—ã\n‚Ä¢ –ï—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω—ã–π, —Ä–∞–∑–≥–æ–≤–æ—Ä–Ω—ã–π —Ç–æ–Ω\n‚Ä¢ –ú—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏",
        "provider_perplexity_description": "–õ—É—á—à–∏–π –≤—ã–±–æ—Ä –¥–ª—è —Ç–µ–∫—É—â–∏—Ö —Å–æ–±—ã—Ç–∏–π –∏ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö –Ω–æ–≤–æ—Å—Ç–µ–π. –í–∫–ª—é—á–∞–µ—Ç –ø–æ–∏—Å–∫ –≤ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–µ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏, –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è—è –∞–∫—Ç—É–∞–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏.",
        "provider_perplexity_strengths": "‚Ä¢ –ü–æ–∏—Å–∫ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏\n‚Ä¢ –°–∞–º–∞—è —Å–≤–µ–∂–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è\n‚Ä¢ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Ü–∏—Ç–∏—Ä—É–µ—Ç –∏—Å—Ç–æ—á–Ω–∏–∫–∏\n‚Ä¢ –û—Ç–ª–∏—á–Ω–æ –¥–ª—è —Å—Ä–æ—á–Ω—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π",

        "view_source": "–û—Ç–∫—Ä—ã—Ç—å –∏—Å—Ç–æ—á–Ω–∏–∫",

        # Chat quick prompts
        "quick_prompts_title": "üí° –ë—ã—Å—Ç—Ä—ã–µ –ü–æ–¥—Å–∫–∞–∑–∫–∏",
        "quick_prompt_why": "–ü–æ—á–µ–º—É —ç—Ç–æ –ª–æ–∂—å/–ø—Ä–∞–≤–¥–∞?",
        "quick_prompt_evidence": "–ü–æ–∫–∞–∂–∏ –¥–æ–∫–∞–∑–∞—Ç–µ–ª—å—Å—Ç–≤–∞",
        "quick_prompt_disagree": "–Ø –Ω–µ —Å–æ–≥–ª–∞—Å–µ–Ω",
        "quick_prompt_msg_why": "–ü–æ–¥—Ä–æ–±–Ω–æ –æ–±—ä—è—Å–Ω–∏—Ç–µ, –ø–æ—á–µ–º—É –≤—ã —Å—á–∏—Ç–∞–µ—Ç–µ —ç—Ç–æ —É—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ –ª–æ–∂–Ω—ã–º –∏–ª–∏ –∏—Å—Ç–∏–Ω–Ω—ã–º.",
        "quick_prompt_msg_evidence": "–ö–∞–∫–∏–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –¥–æ–∫–∞–∑–∞—Ç–µ–ª—å—Å—Ç–≤–∞ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–∞—é—Ç –∏–ª–∏ –æ–ø—Ä–æ–≤–µ—Ä–≥–∞—é—Ç —ç—Ç–æ —É—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ?",
        "quick_prompt_msg_disagree": "–Ø –Ω–µ —Å–æ–≥–ª–∞—Å–µ–Ω —Å –≤–∞—à–µ–π –æ—Ü–µ–Ω–∫–æ–π. –ú–æ–∂–µ—Ç–µ —Ä–∞—Å—Å–º–æ—Ç—Ä–µ—Ç—å –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–µ —Ç–æ—á–∫–∏ –∑—Ä–µ–Ω–∏—è?",

        # Deep analysis
        "source_analysis": "üì∞ –ê–Ω–∞–ª–∏–∑ –ò—Å—Ç–æ—á–Ω–∏–∫–æ–≤",
        "found_fact_checks_count": "–ù–∞–π–¥–µ–Ω–æ –≤–Ω–µ—à–Ω–∏—Ö –ø—Ä–æ–≤–µ—Ä–æ–∫ —Ñ–∞–∫—Ç–æ–≤: {count}",
        "rating_breakdown": "–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –û—Ü–µ–Ω–æ–∫",
        "detailed_sources": "–ü–æ–¥—Ä–æ–±–Ω—ã–µ –ò—Å—Ç–æ—á–Ω–∏–∫–∏",
        "source_item": "–ò—Å—Ç–æ—á–Ω–∏–∫ {idx}: {publisher}",
        "rating_label": "–†–µ–π—Ç–∏–Ω–≥",
        "claim_label": "–£—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ",
        "url_label": "URL",
        "review_date_label": "–î–∞—Ç–∞ –ü—Ä–æ–≤–µ—Ä–∫–∏",
        "no_external_sources": "–í–Ω–µ—à–Ω–∏–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã. –í–æ–∑–º–æ–∂–Ω–æ, —É—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ —Å–ª–∏—à–∫–æ–º –Ω–æ–≤–æ–µ –∏–ª–∏ —Å–ª–∏—à–∫–æ–º —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω–æ–µ.",
        "model_confidence": "üéØ –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –ú–æ–¥–µ–ª–∏",
        "text_statistics": "üìà –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –¢–µ–∫—Å—Ç–∞",
        "characters": "–°–∏–º–≤–æ–ª—ã",
        "words": "–°–ª–æ–≤–∞",
        "sentences": "–ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è",
        "avg_word_length": "–°—Ä–µ–¥–Ω—è—è –î–ª–∏–Ω–∞ –°–ª–æ–≤–∞",
        "key_topics": "üè∑Ô∏è –ö–ª—é—á–µ–≤—ã–µ –¢–µ–º—ã",
        "no_keywords_identified": "–ó–Ω–∞—á–∏–º—ã–µ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω—ã",
        "provider_changed_run_again": "–ü—Ä–æ–≤–∞–π–¥–µ—Ä LLM –∏–∑–º–µ–Ω—ë–Ω. –ù–∞–∂–º–∏—Ç–µ '–ó–∞–ø—É—Å—Ç–∏—Ç—å –ê–Ω–∞–ª–∏–∑' –¥–ª—è –Ω–æ–≤–æ–≥–æ –æ–±—ä—è—Å–Ω–µ–Ω–∏—è.",
    },
    
    "pt": {
        # App title and main UI
        "app_title": "FakeScope ‚Äì Detector de Not√≠cias Falsas",
        "analyze_tab": "üîç Analisar",
        "chat_tab": "üí¨ Chat e Debate",
        "compare_tab": "‚öñÔ∏è Comparar Modelos",
        "deep_analysis_tab": "üìä An√°lise Profunda",
        "dashboard_tab": "üìà Painel",
        
        # Language selector
        "language": "Idioma",
        
        # Analyze section
        "analyze_subtitle": "Analisar um artigo ou afirma√ß√£o",
        "choose_ai_model": "Escolha seu Modelo de IA",
        "llm_provider": "Provedor LLM",
        "why_provider": "Por que",
        "strengths": "Pontos Fortes:",
        "cost": "Custo:",
        "article_url": "URL do artigo (opcional)",
        "title_optional": "T√≠tulo (opcional)",
        "article_text": "Texto do artigo ou afirma√ß√£o",
        "fact_check_language": "Idioma de Verifica√ß√£o",
        "auto_translate": "Traduzir automaticamente para ingl√™s",
        "fetch_from_url": "Obter texto da URL",
        "extracted_text": "Texto extra√≠do",
        "run_analysis": "üöÄ Executar An√°lise",
        "clear": "üóëÔ∏è Limpar",
        "provide_input_error": "‚ö†Ô∏è Por favor, forne√ßa uma URL, t√≠tulo ou texto para analisar.",
        "analyzing": "üîÑ Analisando com",
        "extracted_success": "‚úÖ Texto extra√≠do da URL",
        "extract_failed": "‚ö†Ô∏è N√£o foi poss√≠vel extrair o texto",
        
        # Results section
        "results": "üìä Resultados",
        "verdict": "Veredicto:",
        "true": "VERDADEIRO",
        "fake": "FALSO",
        "credibility_score": "Pontua√ß√£o de Credibilidade",
        "fake_probability": "Probabilidade Falso",
        "true_probability": "Probabilidade Verdadeiro",
        "translated_info": "‚úÖ O texto foi traduzido de {lang} para ingl√™s para an√°lise",
        
        # External fact checks
        "external_fact_checks": "üåê Verifica√ß√µes Externas",
        "google_fact_check_score": "Pontua√ß√£o Google Fact Check",
        "claim": "Afirma√ß√£o",
        "rating": "Classifica√ß√£o",
        "publisher": "Editor",
        "review_date": "Data de Revis√£o",
        "no_fact_checks": "Nenhuma verifica√ß√£o externa encontrada para esta afirma√ß√£o.",
        
        # LLM Explanation
        "llm_explanation": "ü§ñ Explica√ß√£o de IA",
        "provided_by": "Fornecido por",
        
        # Chat section
        "start_conversation": "Iniciar uma conversa sobre a an√°lise",
        "chat_subtitle": "Discutir e debater a credibilidade da sua afirma√ß√£o analisada",
        "analyze_first": "üëà Por favor, execute uma an√°lise primeiro na aba **Analisar**",
        "current_verdict": "Veredicto Atual",
        "your_message": "Sua mensagem",
        "send": "Enviar",
        "chat_history": "Hist√≥rico de Chat",
        
        # Compare models
        "compare_subtitle": "Compare resultados dos tr√™s modelos de IA lado a lado",
        "input_to_compare": "Digite texto para comparar entre modelos",
        "compare_button": "‚öñÔ∏è Comparar Todos os Modelos",
        "comparing": "Comparando entre OpenAI, Gemini e Perplexity...",
        "model_comparison": "Resultados de Compara√ß√£o de Modelos",
        "model": "Modelo",
        "response": "Resposta",
        "response_time": "Tempo de Resposta",
        "seconds": "segundos",
        
        # Deep analysis
        "deep_analysis_subtitle": "Obtenha an√°lise abrangente com fontes e not√≠cias relacionadas",
        "deep_analysis_button": "üîç Executar An√°lise Profunda",
        "deep_analyzing": "Executando an√°lise profunda...",
        "sources_found": "Fontes Encontradas",
        "related_articles": "Artigos Relacionados",
        "sentiment_analysis": "An√°lise de Sentimento",
        "key_entities": "Entidades Principais",
        
        # Dashboard
        "dashboard_subtitle": "An√°lises recentes e estat√≠sticas",
        "recent_analyses": "An√°lises Recentes",
        "no_data": "Nenhum dado dispon√≠vel ainda. Execute algumas an√°lises primeiro!",
        "total_analyses": "Total de An√°lises",
        "avg_credibility": "Credibilidade M√©dia",
        "most_used_provider": "Provedor Mais Usado",

        # Provider details
        "provider_openai_description": "Melhor para an√°lises estruturadas e confi√°veis. Excelente em seguir instru√ß√µes e gerar explica√ß√µes bem formatadas.",
        "provider_openai_strengths": "‚Ä¢ Qualidade consistente\n‚Ä¢ Respostas r√°pidas (1-2s)\n‚Ä¢ Excelente para verifica√ß√£o profissional",
        "provider_gemini_description": "Melhor para alto volume e economia. Camada gratuita com 1.500 solicita√ß√µes/dia. R√°pido e com compreens√£o natural da linguagem.",
        "provider_gemini_strengths": "‚Ä¢ Camada GR√ÅTIS dispon√≠vel\n‚Ä¢ Respostas muito r√°pidas\n‚Ä¢ Tom natural e conversacional\n‚Ä¢ Capaz de multimodal",
        "provider_perplexity_description": "Melhor para eventos atuais e not√≠cias recentes. Inclui busca na web em tempo real, fornecendo contexto atualizado e fontes adicionais.",
        "provider_perplexity_strengths": "‚Ä¢ Busca na web em tempo real\n‚Ä¢ Informa√ß√µes mais recentes\n‚Ä¢ Cita fontes automaticamente\n‚Ä¢ √ìtimo para not√≠cias de √∫ltima hora",

        "view_source": "Ver Fonte",

        # Chat quick prompts
        "quick_prompts_title": "üí° Sugest√µes R√°pidas",
        "quick_prompt_why": "Por que √© falso/verdadeiro?",
        "quick_prompt_evidence": "Mostre-me evid√™ncias",
        "quick_prompt_disagree": "Eu discordo",
        "quick_prompt_msg_why": "Explique em detalhe por que voc√™ acha que esta afirma√ß√£o √© falsa ou verdadeira.",
        "quick_prompt_msg_evidence": "Que evid√™ncias espec√≠ficas apoiam ou contradizem esta afirma√ß√£o?",
        "quick_prompt_msg_disagree": "Eu discordo da sua avalia√ß√£o. Voc√™ pode considerar perspectivas alternativas?",

        # Deep analysis
        "source_analysis": "üì∞ An√°lise de Fontes",
        "found_fact_checks_count": "{count} verifica√ß√µes externas encontradas",
        "rating_breakdown": "Distribui√ß√£o de Classifica√ß√µes",
        "detailed_sources": "Fontes Detalhadas",
        "source_item": "Fonte {idx}: {publisher}",
        "rating_label": "Classifica√ß√£o",
        "claim_label": "Afirma√ß√£o",
        "url_label": "URL",
        "review_date_label": "Data de Revis√£o",
        "no_external_sources": "Nenhuma fonte externa encontrada. Esta afirma√ß√£o pode ser muito recente ou muito espec√≠fica.",
        "model_confidence": "üéØ Confian√ßa do Modelo",
        "text_statistics": "üìà Estat√≠sticas do Texto",
        "characters": "Caracteres",
        "words": "Palavras",
        "sentences": "Frases",
        "avg_word_length": "Tamanho M√©dio da Palavra",
        "key_topics": "üè∑Ô∏è T√≥picos Chave",
        "no_keywords_identified": "Nenhuma palavra-chave significativa identificada",
        "provider_changed_run_again": "Provedor LLM alterado. Clique em 'Executar An√°lise' para uma nova explica√ß√£o.",
    },
}

# Country code to language mapping for IP-based detection
COUNTRY_TO_LANGUAGE = {
    "ES": "es",  # Spain
    "MX": "es",  # Mexico
    "AR": "es",  # Argentina
    "CO": "es",  # Colombia
    "PE": "es",  # Peru
    "VE": "es",  # Venezuela
    "CL": "es",  # Chile
    "EC": "es",  # Ecuador
    "GT": "es",  # Guatemala
    "CU": "es",  # Cuba
    "BO": "es",  # Bolivia
    "DO": "es",  # Dominican Republic
    "HN": "es",  # Honduras
    "PY": "es",  # Paraguay
    "SV": "es",  # El Salvador
    "NI": "es",  # Nicaragua
    "CR": "es",  # Costa Rica
    "PA": "es",  # Panama
    "UY": "es",  # Uruguay
    
    "FR": "fr",  # France
    "BE": "fr",  # Belgium
    "CH": "fr",  # Switzerland
    "LU": "fr",  # Luxembourg
    "MC": "fr",  # Monaco
    "CA": "fr",  # Canada (partial)
    
    "DE": "de",  # Germany
    "AT": "de",  # Austria
    "LI": "de",  # Liechtenstein
    
    "RU": "ru",  # Russia
    "BY": "ru",  # Belarus
    "KZ": "ru",  # Kazakhstan
    "KG": "ru",  # Kyrgyzstan
    
    "PT": "pt",  # Portugal
    "BR": "pt",  # Brazil
    "AO": "pt",  # Angola
    "MZ": "pt",  # Mozambique
}

SUPPORTED_LANGUAGES = ["en", "es", "fr", "de", "ru", "pt"]


def get_country_from_ip(ip: Optional[str] = None) -> Optional[str]:
    """
    Detect country from IP address using ip-api.com (free, no key required).
    Returns ISO country code (e.g., 'US', 'ES', 'FR') or None if detection fails.
    """
    if not ip or ip in ["127.0.0.1", "localhost", "::1"]:
        return None
    
    try:
        # Use ip-api.com free tier (45 requests/minute limit)
        response = requests.get(f"http://ip-api.com/json/{ip}", timeout=2)
        if response.ok:
            data = response.json()
            if data.get("status") == "success":
                return data.get("countryCode")
    except Exception:
        pass
    
    return None


def detect_language_from_ip(ip: Optional[str] = None) -> str:
    """
    Detect preferred language based on visitor's IP address.
    Returns language code ('en', 'es', 'fr', 'de', 'ru', 'pt') with 'en' as default.
    """
    country = get_country_from_ip(ip)
    if country and country in COUNTRY_TO_LANGUAGE:
        lang = COUNTRY_TO_LANGUAGE[country]
        if lang in SUPPORTED_LANGUAGES:
            return lang
    
    return "en"  # Default to English


def get_translation(key: str, language: str = "en", **kwargs) -> str:
    """
    Get translated text for a given key and language.
    
    Args:
        key: Translation key (e.g., 'app_title', 'analyze_tab')
        language: Language code ('en', 'es', 'fr', 'de', 'ru', 'pt')
        **kwargs: Variables to format into the translation (e.g., lang='ES')
    
    Returns:
        Translated string, falling back to English if translation not found
    """
    if language not in TRANSLATIONS:
        language = "en"
    
    text = TRANSLATIONS[language].get(key, TRANSLATIONS["en"].get(key, key))
    
    # Apply formatting if kwargs provided
    if kwargs:
        try:
            text = text.format(**kwargs)
        except Exception:
            pass
    
    return text


def get_language_name(code: str) -> str:
    """Get the full language name for a language code."""
    names = {
        "en": "English",
        "es": "Espa√±ol",
        "fr": "Fran√ßais",
        "de": "Deutsch",
        "ru": "–†—É—Å—Å–∫–∏–π",
        "pt": "Portugu√™s",
    }
    return names.get(code, code)
