app = "fakescope"
primary_region = "iad"

[build]

[env]
  PORT = "8080"
  FAKESCOPE_DB_PATH = "/data/predictions.db"
  # Model downloads to /data and is cached between deployments
  HF_HOME = "/data/.cache/huggingface"

[mounts]
  source = "fakescope_data"
  destination = "/data"

[vm]
  memory = "2gb"
  cpu_kind = "shared"
  cpus = 1

[[services]]
  internal_port = 8080
  processes = ["app"]
  protocol = "tcp"

  [[services.ports]]
    handlers = ["http"]
    port = 80

  [[services.ports]]
    handlers = ["tls", "http"]
    port = 443

  [services.concurrency]
    type = "connections"
    hard_limit = 50
    soft_limit = 25

  [[services.checks]]
    name = "web"
    type = "http"
    interval = "15s"
    timeout = "2s"
    path = "/"
